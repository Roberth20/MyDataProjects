# Worldwide Consumption of Coffee

This project demonstrates the application of Data Cleaning and Transformation techniques to conduct an Exploratory Data Analysis (EDA) on a dataset containing over 20 years of coffee consumption data.

## About
### Inside the notebooks

The notebook begins with the process of cleaning and transforming the dataset using `pandas`. A specific data issue is thoroughly examined, showcasing the analytical approach taken to resolve inconsistencies in the entries. This experience significantly enhanced my problem-solving skills and ability to handle data anomalies.

In the **Analysis** section, I delve into the data to uncover insights such as the Most Consumed Coffee Types, Consumption Trends Over the Years, Most Expensive Coffee Varieties, Average Prices, and more. Finally, I provide an explanation of why this dataset is not suitable for Machine Learning applications, supported by relevant reasoning.

### Web app

The findings were utilized to develop an interactive web application using **Dash**, enabling users to easily explore and visualize the data.

## Installation
To get started with the project, you'll need to clone the repository, set up a conda environment and install the necessary dependencies. Here, you can see how to set up the environment
  ```
  conda env create --file environment.yml
  ```

## Usage
The notebook contains a detailed walkthrough of process and to start it you must follow the below steps:
1. Navigate to this project directory:
```
cd path/to/directory
```
2. Open the jupyter notebook
```
jupyter notebook analysis.ipynb
```

## Data Source
There is a copy of data used inside **data** folder and the original is found in Kaggle following this [link](https://www.kaggle.com/datasets/waqi786/worldwide-coffee-habits-dataset/data).